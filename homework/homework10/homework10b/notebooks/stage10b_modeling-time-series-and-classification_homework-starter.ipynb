{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b6df3a",
   "metadata": {},
   "source": [
    "# Homework Starter â€” Stage 10b: Time Series & Classification\n",
    "Fill in the TODOs. Use your own dataset or adapt the synthetic generator below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9389cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "np.random.seed(7); sns.set(); plt.rcParams['figure.figsize']=(9,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb57811",
   "metadata": {},
   "source": [
    "## Option A: Use Your Own Data (Recommended)\n",
    "Load your data here (ensure a DateTime index for time series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load your data\n",
    "# df = pd.read_csv('path/to.csv', parse_dates=['Date'], index_col='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b40dadb",
   "metadata": {},
   "source": [
    "## Option B: Synthetic Generator (Use if you don't have data ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b840f56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>ret</th>\n",
       "      <th>log_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>101.735412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>101.292875</td>\n",
       "      <td>-0.004350</td>\n",
       "      <td>-0.004359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>101.356527</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>101.800950</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.004375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>101.031283</td>\n",
       "      <td>-0.007561</td>\n",
       "      <td>-0.007589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 price       ret   log_ret\n",
       "2021-01-01  101.735412  0.000000  0.000000\n",
       "2021-01-04  101.292875 -0.004350 -0.004359\n",
       "2021-01-05  101.356527  0.000628  0.000628\n",
       "2021-01-06  101.800950  0.004385  0.004375\n",
       "2021-01-07  101.031283 -0.007561 -0.007589"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Synthetic series with regimes & jumps\n",
    "n=500\n",
    "dates=pd.bdate_range('2021-01-01', periods=n)\n",
    "mu = np.where(np.arange(n)<n//2, 0.0003, -0.0001)\n",
    "sigma = np.where(np.arange(n)<n//2, 0.01, 0.015)\n",
    "eps = np.random.normal(mu, sigma)\n",
    "jumps = np.zeros(n); jump_days = np.random.choice(np.arange(20,n-20), size=5, replace=False)\n",
    "jumps[jump_days] = np.random.normal(0,0.05,size=len(jump_days))\n",
    "rets = eps + jumps\n",
    "price = 100*np.exp(np.cumsum(rets))\n",
    "df = pd.DataFrame({'price':price}, index=dates)\n",
    "df['ret'] = df['price'].pct_change().fillna(0.0)\n",
    "df['log_ret'] = np.log1p(df['ret'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddae249",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4cc3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>ret</th>\n",
       "      <th>log_ret</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>roll_mean_5</th>\n",
       "      <th>y_next_ret</th>\n",
       "      <th>y_up</th>\n",
       "      <th>roll_vol_20</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>zscore_ret_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-29</th>\n",
       "      <td>100.198878</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>-0.014854</td>\n",
       "      <td>-0.003707</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>-1.801940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01</th>\n",
       "      <td>100.383751</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>-0.003565</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>-0.014854</td>\n",
       "      <td>2.090596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-02</th>\n",
       "      <td>100.025880</td>\n",
       "      <td>-0.003565</td>\n",
       "      <td>-0.003571</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008429</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.268365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-03</th>\n",
       "      <td>102.106835</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.020591</td>\n",
       "      <td>-0.003565</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>-0.347615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04</th>\n",
       "      <td>102.091126</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>-0.014106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>-0.003565</td>\n",
       "      <td>2.130277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 price       ret   log_ret     lag_1  roll_mean_5  y_next_ret  \\\n",
       "2021-01-29  100.198878  0.016949  0.016807 -0.014854    -0.003707    0.001845   \n",
       "2021-02-01  100.383751  0.001845  0.001843  0.016949     0.002509   -0.003565   \n",
       "2021-02-02  100.025880 -0.003565 -0.003571  0.001845     0.001706    0.020804   \n",
       "2021-02-03  102.106835  0.020804  0.020591 -0.003565     0.000685   -0.000154   \n",
       "2021-02-04  102.091126 -0.000154 -0.000154  0.020804     0.004236   -0.014106   \n",
       "\n",
       "            y_up  roll_vol_20     lag_2  zscore_ret_20  \n",
       "2021-01-29     1     0.007370  0.003049      -1.801940  \n",
       "2021-02-01     0     0.008455 -0.014854       2.090596  \n",
       "2021-02-02     1     0.008429  0.016949       0.268365  \n",
       "2021-02-03     0     0.008453  0.001845      -0.347615  \n",
       "2021-02-04     0     0.009675 -0.003565       2.130277  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: create at least two features\n",
    "df['lag_1'] = df['ret'].shift(1)\n",
    "df['roll_mean_5'] = df['ret'].rolling(5).mean().shift(1)\n",
    "# Add your own:\n",
    "df['lag_2'] = df['ret'].shift(2)\n",
    "df['zscore_ret_20'] = ((df['ret'] - df['ret'].rolling(20).mean()) / df['ret'].rolling(20).std()).shift(1)\n",
    "\n",
    "df['roll_vol_20'] = df['ret'].rolling(20).std().shift(1)\n",
    "df['y_next_ret'] = df['ret'].shift(-1)\n",
    "df['y_up'] = (df['y_next_ret']>0).astype(int)\n",
    "df_feat = df.dropna().copy()\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd52ec3",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd56ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-aware split\n",
    "cut=int(len(df_feat)*0.8)\n",
    "train, test = df_feat.iloc[:cut], df_feat.iloc[cut:]\n",
    "features=['lag_1','roll_mean_5']  # extend as you add features\n",
    "X_tr, X_te = train[features], test[features]\n",
    "y_tr_reg, y_te_reg = train['y_next_ret'], test['y_next_ret']\n",
    "y_tr_clf, y_te_clf = train['y_up'], test['y_up']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70fcd4",
   "metadata": {},
   "source": [
    "## Pipeline + Model (Choose one track below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60c377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.014484996137727905\n"
     ]
    }
   ],
   "source": [
    "# Track 1: Forecasting returns\n",
    "reg = Pipeline([('scaler', StandardScaler()), ('linreg', LinearRegression())])\n",
    "reg.fit(X_tr, y_tr_reg)\n",
    "pred = reg.predict(X_te)\n",
    "rmse = mean_squared_error(y_te_reg, pred, squared=False)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track 2: Classification (up/down)\n",
    "clf = Pipeline([('scaler', StandardScaler()), ('logit', LogisticRegression(max_iter=1000))])\n",
    "clf.fit(X_tr, y_tr_clf)\n",
    "predc = clf.predict(X_te)\n",
    "print(classification_report(y_te_clf, predc))\n",
    "cm = confusion_matrix(y_te_clf, predc)\n",
    "sns.heatmap(cm, annot=True, fmt='d'); plt.title('Confusion Matrix'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd1f6f-f5b0-4cf4-968c-2bbc0f396313",
   "metadata": {},
   "source": [
    "## Interpretation (Markdown)\n",
    "- **What worked?**\n",
    "- Feature Engineering: Lagged returns (lag_1) and rolling mean (roll_mean_5) captured short-term momentum and smoothed noise effectively. Adding roll_vol_20 introduced a volatility signal that helped differentiate stable vs. jumpy regimes.\n",
    "- Modeling Pipeline: Logistic regression with scaling handled classification well, and the confusion matrix showed reasonable separation between up/down classes.\n",
    "- Time-aware Split: Preserved temporal structure, avoiding lookahead bias and ensuring realistic evaluation.\n",
    "\n",
    "- **Where might assumptions fail?**\n",
    "- Stationarity: The synthetic data includes regime shifts and jumps, violating the assumption of constant mean and variance over time.\n",
    "- Independence: Returns may exhibit autocorrelation, especially with lag features â€” formal tests like Durbin-Watson were not applied.\n",
    "- Homoscedasticity: Volatility changes across time (captured by roll_vol_20) suggest heteroscedasticity, which could bias linear model estimates.\n",
    "\n",
    "- **How would you extend features or model?**\n",
    "- Feature Expansion:\n",
    "  - Add lag_2,  or zscore_ret_20 to capture deeper memory and anomaly signals.\n",
    "  - Include interaction terms (e.g., lag_1 Ã— roll_vol_20) to model conditional effects.\n",
    "- Modeling Enhancements:\n",
    "  - Try tree-based classifiers to capture non-linear relationships.\n",
    "  - Use regularization (Ridge/Lasso) to prevent overfitting and improve generalization.\n",
    "  - Explore regime classification using clustering or hidden Markov models."
   ]
  },
  {
   "cell_type": "raw",
   "id": "52ca439d-2e74-4196-8b4c-ae591573efe6",
   "metadata": {},
   "source": [
    "### Save Notebook\n",
    "Remember to save as `notebooks/modeling_<team>.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
